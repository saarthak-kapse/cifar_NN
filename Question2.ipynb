{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./image_data/', \n",
    "                                        train=True,\n",
    "                                        download=True, \n",
    "                                        transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./image_data', \n",
    "                                       train=False,\n",
    "                                       download=True, \n",
    "                                       transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, \n",
    "                                         batch_size=1,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# classes = ('plane', 'car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network_50(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(neural_network_50, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=60, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=60, out_channels=120, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = torch.nn.Linear(120 * 4 * 4, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 120 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranining of Epoch: 0  Done\n",
      "epoch: 1 , Train Loss: 268.21 , Test Loss: 29.983 , Test Accuracy: 87.7 %\n",
      "Tranining of Epoch: 1  Done\n",
      "epoch: 2 , Train Loss: 126.086 , Test Loss: 19.208 , Test Accuracy: 91.65 %\n",
      "Tranining of Epoch: 2  Done\n",
      "epoch: 3 , Train Loss: 82.421 , Test Loss: 14.273 , Test Accuracy: 94.4 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-6ed5fe96592f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0moutput_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mtraining_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_network = neural_network_50()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(my_network.parameters(), lr=0.1)\n",
    "# optimizer = optim.SGD(my_network.parameters(), lr=0.1)\n",
    "\n",
    "model_directory_path = './PyTorch_model'\n",
    "model_path = model_directory_path + '/cifar10_50_percent.pt'\n",
    "\n",
    "if not os.path.exists(model_directory_path):\n",
    "    os.makedirs(model_directory_path)\n",
    "\n",
    "# if os.path.isfile(model_path):\n",
    "#     my_network.load_state_dict(torch.load(model_path))\n",
    "#     print('Pre Trained model exist, Loading')\n",
    "# else:\n",
    "\n",
    "train_continue = True\n",
    "early_stopping = np.zeros(3)\n",
    "count = 0\n",
    "previous_loss = float('Inf')\n",
    "\n",
    "while(train_continue==True):\n",
    "\n",
    "    training_loss = 0.0\n",
    "    testing_loss = 0.0\n",
    "    total_correct_test = 0\n",
    "    total_image_test = 0\n",
    "\n",
    "    for train_data in trainloader:\n",
    "        input_batch, label_batch = train_data\n",
    "        input_batch = input_batch[label_batch<2]\n",
    "        if np.array(input_batch).shape[0] == 0:\n",
    "            continue\n",
    "        label_batch = label_batch[label_batch<2]\n",
    "        optimizer.zero_grad()\n",
    "        output_batch = my_network(input_batch)\n",
    "        loss = criterion(output_batch, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "\n",
    "    print('Tranining of Epoch:', count,' Done')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_data_batch in testloader:\n",
    "            input_batch, label_batch = test_data_batch\n",
    "            input_batch = input_batch[label_batch<2]\n",
    "            if np.array(input_batch).shape[0] == 0:\n",
    "                continue\n",
    "            label_batch = label_batch[label_batch<2]\n",
    "            output_batch = my_network(input_batch)\n",
    "            loss = criterion(output_batch, label_batch)\n",
    "            testing_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(output_batch.data, 1)\n",
    "            total_image_test += label_batch.size(0)\n",
    "            total_correct_test += (predicted == label_batch).sum().item()\n",
    "        test_accuracy = round(total_correct_test / total_image_test * 100,3)\n",
    "\n",
    "    if testing_loss<previous_loss:\n",
    "        previous_loss = testing_loss\n",
    "        torch.save(my_network.state_dict(), model_path)  \n",
    "\n",
    "    if (testing_loss-previous_loss)>=0.01:\n",
    "        early_stopping[count%3] = 1\n",
    "    else:\n",
    "        early_stopping[count%3] = 0\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    if np.sum(early_stopping) == 3:\n",
    "        train_continue = False\n",
    "\n",
    "    print('epoch:',count ,', Train Loss:', round(training_loss,3),', Test Loss:', round(testing_loss,3),', Test Accuracy:', round(test_accuracy,3),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.403\n"
     ]
    }
   ],
   "source": [
    "my_network = neural_network_50()\n",
    "\n",
    "model_directory_path = './PyTorch_model'\n",
    "model_path = model_directory_path + '/cifar10_50_percent.pt'\n",
    "\n",
    "my_network.load_state_dict(torch.load(model_path))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data_batch in testloader:\n",
    "        input_batch, label_batch = test_data_batch\n",
    "        input_batch = input_batch[label_batch<2]\n",
    "        if np.array(input_batch).shape[0] == 0:\n",
    "            continue\n",
    "        label_batch = label_batch[label_batch<2]\n",
    "        output_batch = my_network(input_batch)\n",
    "        _, predicted = torch.max(output_batch.data, 1)\n",
    "        total_image_test += label_batch.size(0)\n",
    "        total_correct_test += (predicted == label_batch).sum().item()\n",
    "    test_accuracy = round(total_correct_test / total_image_test * 100,3)\n",
    "\n",
    "    print('Accuracy:',test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network_25(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(neural_network_25, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=30, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=30, out_channels=60, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = torch.nn.Linear(60 * 4 * 4, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 60 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranining of Epoch: 0  Done\n",
      "epoch: 1 , Train Loss: 257.198 , Test Loss: 35.257 , Test Accuracy: 85.2 %\n",
      "Tranining of Epoch: 1  Done\n",
      "epoch: 2 , Train Loss: 181.108 , Test Loss: 32.341 , Test Accuracy: 86.15 %\n",
      "Tranining of Epoch: 2  Done\n",
      "epoch: 3 , Train Loss: 162.614 , Test Loss: 28.592 , Test Accuracy: 88.25 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-feeabc183713>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mlabel_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0moutput_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-5648e4d7e604>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_network = neural_network_25()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(my_network.parameters(), lr=0.0001)\n",
    "# optimizer = optim.Adam(my_network.parameters(), lr=0.0001)\n",
    "\n",
    "model_directory_path = './PyTorch_model'\n",
    "model_path = model_directory_path + '/cifar10_25_percent.pt'\n",
    "\n",
    "if not os.path.exists(model_directory_path):\n",
    "    os.makedirs(model_directory_path)\n",
    "\n",
    "# if os.path.isfile(model_path):\n",
    "#     my_network.load_state_dict(torch.load(model_path))\n",
    "#     print('Pre Trained model exist, Loading')\n",
    "# else:\n",
    "\n",
    "train_continue = True\n",
    "early_stopping = np.zeros(3)\n",
    "count = 0\n",
    "previous_loss = float('Inf')\n",
    "\n",
    "while(train_continue==True):\n",
    "\n",
    "    training_loss = 0.0\n",
    "    testing_loss = 0.0\n",
    "    total_correct_test = 0\n",
    "    total_image_test = 0\n",
    "\n",
    "    for train_data in trainloader:\n",
    "        input_batch, label_batch = train_data\n",
    "        input_batch = input_batch[label_batch<2]\n",
    "        if np.array(input_batch).shape[0] == 0:\n",
    "            continue\n",
    "        label_batch = label_batch[label_batch<2]\n",
    "        optimizer.zero_grad()\n",
    "        output_batch = my_network(input_batch)\n",
    "        loss = criterion(output_batch, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "\n",
    "    print('Tranining of Epoch:', count,' Done')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_data_batch in testloader:\n",
    "            input_batch, label_batch = test_data_batch\n",
    "            input_batch = input_batch[label_batch<2]\n",
    "            if np.array(input_batch).shape[0] == 0:\n",
    "                continue\n",
    "            label_batch = label_batch[label_batch<2]\n",
    "            output_batch = my_network(input_batch)\n",
    "            loss = criterion(output_batch, label_batch)\n",
    "            testing_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(output_batch.data, 1)\n",
    "            total_image_test += label_batch.size(0)\n",
    "            total_correct_test += (predicted == label_batch).sum().item()\n",
    "        test_accuracy = round(total_correct_test / total_image_test * 100,3)\n",
    "\n",
    "    if testing_loss<previous_loss:\n",
    "        previous_loss = testing_loss\n",
    "        torch.save(my_network.state_dict(), model_path)  \n",
    "\n",
    "    if (testing_loss-previous_loss)>=0.01:\n",
    "        early_stopping[count%3] = 1\n",
    "    else:\n",
    "        early_stopping[count%3] = 0\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    if np.sum(early_stopping) == 3:\n",
    "        train_continue = False\n",
    "\n",
    "    print('epoch:',count ,', Train Loss:', round(training_loss,3),', Test Loss:', round(testing_loss,3),', Test Accuracy:', round(test_accuracy,3),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.192\n"
     ]
    }
   ],
   "source": [
    "my_network = neural_network_25()\n",
    "\n",
    "model_directory_path = './PyTorch_model'\n",
    "model_path = model_directory_path + '/cifar10_25_percent.pt'\n",
    "\n",
    "my_network.load_state_dict(torch.load(model_path))\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for test_data_batch in testloader:\n",
    "        input_batch, label_batch = test_data_batch\n",
    "        input_batch = input_batch[label_batch<2]\n",
    "        if np.array(input_batch).shape[0] == 0:\n",
    "            continue\n",
    "        label_batch = label_batch[label_batch<2]\n",
    "        output_batch = my_network(input_batch)\n",
    "        _, predicted = torch.max(output_batch.data, 1)\n",
    "        total_image_test += label_batch.size(0)\n",
    "        total_correct_test += (predicted == label_batch).sum().item()\n",
    "    test_accuracy = round(total_correct_test / total_image_test * 100,3)\n",
    "    print('Accuracy:',test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80904"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(my_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
